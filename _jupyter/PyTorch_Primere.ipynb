{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch > TensorFlow",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S23tUXpyjRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfyUpNZ6yvAZ",
        "colab_type": "code",
        "outputId": "0851b9e3-4f7b-4836-e486-fc53f997fbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# cannot use np.float32 or np.float64 with torch tensors\n",
        "a = torch.arange(0, 50, step=1, dtype=torch.float64).reshape(10,5)\n",
        "print(a)\n",
        "print(a.dtype)\n",
        "print(a.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
            "        [ 5.,  6.,  7.,  8.,  9.],\n",
            "        [10., 11., 12., 13., 14.],\n",
            "        [15., 16., 17., 18., 19.],\n",
            "        [20., 21., 22., 23., 24.],\n",
            "        [25., 26., 27., 28., 29.],\n",
            "        [30., 31., 32., 33., 34.],\n",
            "        [35., 36., 37., 38., 39.],\n",
            "        [40., 41., 42., 43., 44.],\n",
            "        [45., 46., 47., 48., 49.]], dtype=torch.float64)\n",
            "torch.float64\n",
            "torch.Size([10, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXlGbwdpy7n4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpy_style_a = a.numpy() # convert to numpy style array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hc2mbte9SBt",
        "colab_type": "code",
        "outputId": "0ad24d99-64a5-4a6e-db42-e9fad726d5f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "numpy_style_a"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  1.,  2.,  3.,  4.],\n",
              "       [ 5.,  6.,  7.,  8.,  9.],\n",
              "       [10., 11., 12., 13., 14.],\n",
              "       [15., 16., 17., 18., 19.],\n",
              "       [20., 21., 22., 23., 24.],\n",
              "       [25., 26., 27., 28., 29.],\n",
              "       [30., 31., 32., 33., 34.],\n",
              "       [35., 36., 37., 38., 39.],\n",
              "       [40., 41., 42., 43., 44.],\n",
              "       [45., 46., 47., 48., 49.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGzeH30I9T0f",
        "colab_type": "code",
        "outputId": "2961069c-60ed-44e4-aeef-54fa9e622885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# convert numpy to torch style tensor\n",
        "numpy_style_to_torch_style_a = torch.from_numpy(numpy_style_a)\n",
        "print(numpy_style_to_torch_style_a)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
            "        [ 5.,  6.,  7.,  8.,  9.],\n",
            "        [10., 11., 12., 13., 14.],\n",
            "        [15., 16., 17., 18., 19.],\n",
            "        [20., 21., 22., 23., 24.],\n",
            "        [25., 26., 27., 28., 29.],\n",
            "        [30., 31., 32., 33., 34.],\n",
            "        [35., 36., 37., 38., 39.],\n",
            "        [40., 41., 42., 43., 44.],\n",
            "        [45., 46., 47., 48., 49.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeyIYvwO91Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.from_numpy(np.random.randn(5, 3)) # Lets generate 2 random tensors\n",
        "b = torch.from_numpy(np.random.randn(3, 5)) # and operate on them"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDh-gTDfvG_V",
        "colab_type": "code",
        "outputId": "5d603459-6f3f-44ad-c5ea-2aa6c98a6718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "print(f\"{a}\\n{b}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1307, -1.2265, -0.2573],\n",
            "        [ 0.8084,  0.8649, -0.9348],\n",
            "        [-0.6927, -0.6982, -0.3498],\n",
            "        [ 0.5369, -1.2325,  0.6463],\n",
            "        [ 0.1248, -0.8058,  1.8803]], dtype=torch.float64)\n",
            "tensor([[ 0.0721, -0.8766, -0.6709,  1.0116, -0.0801],\n",
            "        [ 0.3031,  0.1315, -0.6130,  1.5394,  0.9872],\n",
            "        [ 0.2359, -0.1943,  1.3411,  1.4563, -0.4084]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5em3PuDJvo0B",
        "colab_type": "code",
        "outputId": "64963b8a-7673-40bb-f02f-805a04392242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# to add,subtract use a+b,a-b\n",
        "# for matrix multiplication\n",
        "c = a @ b # @ -> matrix multiplication\n",
        "print(c)\n",
        "c = torch.mm(a, b) # Equivalent to a@b\n",
        "print(c)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.4419,  0.0033,  0.4945, -2.3951, -1.0953],\n",
            "        [ 0.0999, -0.4132, -2.3263,  0.7879,  1.1709],\n",
            "        [-0.3441,  0.5833,  0.4236, -2.2850, -0.4910],\n",
            "        [-0.1824, -0.7584,  1.2620, -0.4129, -1.5236],\n",
            "        [ 0.2083, -0.5807,  2.9319,  1.6239, -1.5735]], dtype=torch.float64)\n",
            "tensor([[-0.4419,  0.0033,  0.4945, -2.3951, -1.0953],\n",
            "        [ 0.0999, -0.4132, -2.3263,  0.7879,  1.1709],\n",
            "        [-0.3441,  0.5833,  0.4236, -2.2850, -0.4910],\n",
            "        [-0.1824, -0.7584,  1.2620, -0.4129, -1.5236],\n",
            "        [ 0.2083, -0.5807,  2.9319,  1.6239, -1.5735]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYgzjKazwKCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making tensors on GPU :o\n",
        "# See the RAM bar will increase as soon as we create a tensor on GPU\n",
        "a_gpu = torch.arange(0, 50, dtype=torch.float64, device='cuda').reshape(5, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnfNts_LwtHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "5eb495db-d4b0-4a79-b3b2-d2cbfb0046b2"
      },
      "source": [
        "a_gpu"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
              "        [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
              "        [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n",
              "        [30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n",
              "        [40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]], device='cuda:0',\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai1YLLfDWevW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "34415cbd-12ff-4096-ab60-35ca2a930623"
      },
      "source": [
        "# torch.is_tensor\n",
        "print(torch.is_tensor([1., 2., 3.]))\n",
        "print(torch.is_tensor(a))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbFnvrpOWwyg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "29639fec-7995-43d7-fcaf-34691d0c8f65"
      },
      "source": [
        "# torch.set_default_dtype -> set floating point dtype\n",
        "torch.set_default_dtype(torch.float64)\n",
        "a = torch.linspace(0, 10, 100)\n",
        "print(a.dtype)\n",
        "# torch.get_default_dtype\n",
        "print(torch.get_default_dtype())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float64\n",
            "torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iawr4hAyXANn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3e39114-c903-42f0-8f00-d98fb1a7febb"
      },
      "source": [
        "# torch.numel -> same as np.ndarray.size\n",
        "print(torch.numel(a))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42PEyCm-YG-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d1e7b563-227b-4062-9bae-b2e26ef8ac27"
      },
      "source": [
        "# torch.tensor -> Similar to np.array(data)\n",
        "# ``torch.tensor`` always copies ``data``. To avoid copying\n",
        "# np.ndarray use ``torch.as_tensor`` instead\n",
        "a = torch.tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], device='cuda')\n",
        "print(a)\n",
        "\n",
        "# You can also record gradients on the\n",
        "# operations invloving `a` by setting require_grad=True\n",
        "a = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]], device='cuda', requires_grad=True)\n",
        "b = torch.tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], device='cuda', requires_grad=True)\n",
        "# Operate on a and b\n",
        "c = (a @ b).sum()\n",
        "# The graph formed is:\n",
        "# a     b\n",
        "#  \\   /\n",
        "#    c (op: SumBackward)\n",
        "print(c.grad_fn)\n",
        "print(c.backward()) # This just calculates the gradient of c wrt all the nodes in the graph\n",
        "print(a.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]], device='cuda:0')\n",
            "<SumBackward0 object at 0x7f57d77a72e8>\n",
            "None\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], device='cuda:0')\n",
            "tensor([[12., 12., 12.],\n",
            "        [15., 15., 15.],\n",
            "        [18., 18., 18.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf5j6K-2Yz1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "87951756-bbe2-4a6e-e524-70bd153850a6"
      },
      "source": [
        "# torch.sparse_coo_tensor -> create a sparse tensor ==> amazing\n",
        "a = torch.sparse_coo_tensor(torch.empty([1, 0]),\n",
        "                            torch.empty([0, 2]), [1, 2])\n",
        "print(a)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(indices=tensor([], size=(1, 0)),\n",
            "       values=tensor([], size=(0, 2)),\n",
            "       size=(1, 2), nnz=0, layout=torch.sparse_coo)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85Ril3Lbus7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.as_tensor  -> create a tensor from np.ndarray\n",
        "# torch.as_strided -> np.lib.stride_tricks.as_strided\n",
        "# torch.from_numpy -> as the name suggest\n",
        "# torch.zeros\n",
        "# torch.zeros_like\n",
        "# torch.ones\n",
        "# torch.ones_like\n",
        "# torch.empty\n",
        "# torch.empty_like\n",
        "# torch.full\n",
        "# torch.full_like\n",
        "# torch.arange\n",
        "# torch.linspace\n",
        "# torch.logspace\n",
        "# torch.eye\n",
        "# torch.empty_strided\n",
        "# torch.cat -> np.concatenate\n",
        "# torch.chunk -> Splits a tensor into a specific number of chunks.\n",
        "#                Each chunk is a view of the input tensor\n",
        "# torch.reshape\n",
        "# torch.stack\n",
        "# torch.t -> same as np.ndarray.T ==> Use `torch.tensor.T` instead\n",
        "# torch.transpose\n",
        "# torch.take -> same as np.take\n",
        "# torch.where -> same as np.where"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS4mOdnd7nd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4fc5b42b-1b03-4fbf-92e0-b4b2cc6ad746"
      },
      "source": [
        "# torch.gather -> Gathers values along an axis specified by `dim` (`axis`)\n",
        "a = torch.arange(10)\n",
        "a_gather = torch.gather(a, dim=0, index=torch.tensor([0, 0, 1, 1, 6, 5, 9, 5, 6, 7]))\n",
        "print(a_gather)\n",
        "t = torch.tensor([[1,2],[3,4]])\n",
        "print(torch.gather(t, 1, torch.tensor([[0,0],[1,0]])))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 1, 1, 6, 5, 9, 5, 6, 7])\n",
            "tensor([[1, 1],\n",
            "        [4, 3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plc3ACy5-7w5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "a57a0856-57ec-4819-886c-68be5bcfc0d9"
      },
      "source": [
        "# torch.index_seelct -> select the indices along a given `dim` (`axis`)\n",
        "# This operation creates a copy if the `out` argument is not the same shape\n",
        "# as the input tensor.\n",
        "a = torch.randn(3, 4)\n",
        "print(a)\n",
        "torch.index_select(a, 0, torch.tensor([0, 2]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.8138, -1.6075, -0.2263,  1.1918],\n",
            "        [ 1.0004,  0.5787, -1.0218,  0.5546],\n",
            "        [ 0.6320, -0.3689,  2.0017, -0.2749]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.8138, -1.6075, -0.2263,  1.1918],\n",
              "        [ 0.6320, -0.3689,  2.0017, -0.2749]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv24xIn4-9an",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "8dd1116e-3bd1-44e1-af4c-d7a3997204f8"
      },
      "source": [
        "# torch.masked_select -> selects the masked entries only.\n",
        "# Always creates a copy.\n",
        "a = torch.randn(3, 4)\n",
        "print(a)\n",
        "torch.masked_select(a, a<=0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.5467, -0.1766,  2.1532,  1.2930],\n",
            "        [ 0.1260, -0.4382,  1.0440, -0.3801],\n",
            "        [-2.2948,  0.8406,  0.2105, -1.3414]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1766, -0.4382, -0.3801, -2.2948, -1.3414])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCg9vWLj_ogQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "33154786-e4a3-4378-9f6e-75785ae1b069"
      },
      "source": [
        "# torch.narrow -> Select the entires from the array\n",
        "# along a particular `dim` starting at `start` and\n",
        "# ending at `end`. Signature: input, dim, start, end.\n",
        "# Its a view, not a copy\n",
        "a = torch.randn(3, 4)\n",
        "print(a)\n",
        "torch.narrow(a, 0, 1, 2) # 2 inclusive"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.8803,  0.6273,  0.4604,  0.0672],\n",
            "        [-0.2596, -0.5898,  0.8850,  0.8675],\n",
            "        [ 0.7572, -0.7520,  1.2238, -0.5357]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2596, -0.5898,  0.8850,  0.8675],\n",
              "        [ 0.7572, -0.7520,  1.2238, -0.5357]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMwjAh7NAwWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2f5f62d0-5011-4205-fa46-c696a75cbce9"
      },
      "source": [
        "# torch.reshape -> Creates a view whenever possible\n",
        "# use torch.as_strided for garunteed view.\n",
        "a = torch.randn(1, 2, 3, 4, 5)\n",
        "print(a.shape)\n",
        "torch.reshape(a, [5, 4, 3, 2, 1]).shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2, 3, 4, 5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4, 3, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsLVv5uEB6Kp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "5b7c43d6-f113-4163-94c4-f1e2e30b1cd2"
      },
      "source": [
        "# torch.split -> Splits the tensor into chunks.\n",
        "# Each chunk is a view of the original tensor.\n",
        "a = torch.randn(3, 5)\n",
        "print(a)\n",
        "print(torch.split(a, [1, 4], dim=1)[0])\n",
        "print(torch.split(a, [1, 4], dim=1)[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2909, -0.8594,  0.5405,  0.2805, -1.1462],\n",
            "        [ 0.6899, -0.9686,  0.2591, -0.2129,  0.1239],\n",
            "        [-0.7620,  0.3153, -0.9378,  0.3468, -1.3720]])\n",
            "tensor([[-0.2909],\n",
            "        [ 0.6899],\n",
            "        [-0.7620]])\n",
            "tensor([[-0.8594,  0.5405,  0.2805, -1.1462],\n",
            "        [-0.9686,  0.2591, -0.2129,  0.1239],\n",
            "        [ 0.3153, -0.9378,  0.3468, -1.3720]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueS1jnC-DTio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7d95cc44-efb9-45b7-ff28-242a9ecda76d"
      },
      "source": [
        "# torch.squeeze -> same as np.squeeze\n",
        "a = torch.randn(5, 1, 1, 4, 1, 1, 3, 1, 1, 2)\n",
        "print(a.shape)\n",
        "b = torch.squeeze(a)\n",
        "print(b.shape)\n",
        "# torch.unsqueeze -> wow!\n",
        "torch.unsqueeze(b, -1).shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1, 1, 4, 1, 1, 3, 1, 1, 2])\n",
            "torch.Size([5, 4, 3, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4, 3, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bd_jd2BEldK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e462f4c6-570d-42db-bc9b-a606a1e0249b"
      },
      "source": [
        "# torch.where -> if `condition`, `x`, else `y`\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "torch.where(a>2, a, 1-a)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, -1],\n",
              "        [ 3,  4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63mbiDnHRzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#                       Random Sampling in Torch!!\n",
        "# torch.seed\n",
        "# torch.set_rng_state\n",
        "# torch.get_rng_state\n",
        "# torch.rand\n",
        "# torch.rand_like\n",
        "# torch.randint\n",
        "# torch.randint_like\n",
        "# torch.randn\n",
        "# torch.randn_like\n",
        "# torch.randperm -> Returns a random permutation of integers from `0` to `n-1`.\n",
        "# torch.bernoulli\n",
        "# torch.multinomial\n",
        "# torch.poisson\n",
        "# torch.normal\n",
        "\n",
        "#                       Inplace Random Sampling\n",
        "# =========================     =========================================================\n",
        "#         CODE                                         DOCUMENTATION\n",
        "# =========================     =========================================================\n",
        "# torch.Tensor.bernoulli_()   - in-place version of torch.bernoulli()\n",
        "# torch.Tensor.cauchy_()      - numbers drawn from the Cauchy distribution\n",
        "# torch.Tensor.exponential_() - numbers drawn from the exponential distribution\n",
        "# torch.Tensor.geometric_()   - elements drawn from the geometric distribution\n",
        "# torch.Tensor.log_normal_()  - samples from the log-normal distribution\n",
        "# torch.Tensor.normal_()      - in-place version of torch.normal()\n",
        "# torch.Tensor.random_()      - numbers sampled from the discrete uniform distribution\n",
        "# torch.Tensor.uniform_()     - numbers sampled from the continuous uniform distribution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikteJICdIOAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c0d65e2-f0bc-475a-9eda-60fa7af058d8"
      },
      "source": [
        "# Serialization\n",
        "# torch.save -> Saves tensor objects and model in pickle file\n",
        "# torch.load -> Loads tensor objects and model from a pickle file\n",
        "a = torch.arange(10)\n",
        "torch.save(a, 'torch_tensor_a.pkl')\n",
        "a = torch.load('torch_tensor_a.pkl')\n",
        "a"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcyTevew_7y2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d7c5cfa4-b103-47bf-8e8d-e9a65100292e"
      },
      "source": [
        "# Parallelism\n",
        "# torch.get_num_threads()\n",
        "# torch.set_num_threads()\n",
        "# torch.get_num_inteop_threads()\n",
        "# torch.set_num_interop_threads()\n",
        "print(torch.get_num_threads())\n",
        "torch.set_num_threads(4)\n",
        "print(torch.get_num_threads())\n",
        "torch.set_num_threads(1)\n",
        "print(torch.get_num_threads())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "4\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isfy6fkaAAiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d96c3f8-c0d0-43e4-fa7a-ffb6a747da5c"
      },
      "source": [
        "# torch.no_grad() -> Context manager to disable backprop for\n",
        "#                    some particular operation. This means that\n",
        "#                    the operation will not be recorded on graph.\n",
        "a = torch.arange(10, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "b = torch.arange(10, 20, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "with torch.no_grad():\n",
        "    c = a * b\n",
        "print(c.requires_grad)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEEbwIIhBiHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dda963cb-7fc2-47fe-90b7-13d58c733040"
      },
      "source": [
        "# torch.enable_grad() -> Enablewe grad for operations where grad computation\n",
        "#                        has been altered using torch.no_grad or torch.set_grad_enabled\n",
        "# Method 1\n",
        "a = torch.arange(10, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "b = torch.arange(10, 20, requires_grad=True, dtype=torch.float32, device='cuda')\n",
        "with torch.no_grad():\n",
        "    with torch.enable_grad():\n",
        "        c = a * b\n",
        "print(c.requires_grad)\n",
        "\n",
        "# Method 2\n",
        "@torch.enable_grad()\n",
        "def mul_op(x, y):\n",
        "    return x * y\n",
        "\n",
        "with torch.no_grad():\n",
        "    c = mul_op(a, b)\n",
        "print(c.requires_grad)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6slupOmQCbj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Math operations\n",
        "# torch.abs\n",
        "# torch.acos\n",
        "# torch.asin\n",
        "# torch.atan\n",
        "# torch.atan2\n",
        "# torch.sin\n",
        "# torch.cos\n",
        "# torch.cosh\n",
        "# torch.tanh\n",
        "# torch.sinh\n",
        "# torch.tan\n",
        "# torch.exp\n",
        "# torch.log\n",
        "# torch.log10\n",
        "# torch.log2\n",
        "# torch.pow\n",
        "# torch.div\n",
        "# torch.add\n",
        "# torch.mul\n",
        "# torch.reciprocal\n",
        "# torch.remainder\n",
        "# torch.round\n",
        "# torch.rsqrt\n",
        "# torch.sqrt\n",
        "# torch.sigmoid\n",
        "# torch.sign\n",
        "# torch.square\n",
        "# torch.true_devide\n",
        "# torch.trunc -> truncate a floting point into integer\n",
        "# torch.argmax\n",
        "# torch.argmin\n",
        "# torch.max\n",
        "# torch.min\n",
        "# torch.dist -> Computes the p-norm of a tensor (default p=2)\n",
        "# torch.logsumexp\n",
        "# torch.mean\n",
        "# torch.median\n",
        "# torch.mode\n",
        "# torch.std\n",
        "# torch.std_mean\n",
        "# torch.var\n",
        "# torch.var_mean\n",
        "# torch.sum\n",
        "# torch.prod\n",
        "# torch.cumsum\n",
        "# torch.cumprod\n",
        "# torch.unique\n",
        "# torch.diag -> same as np.diag\n",
        "# torch.cholesky\n",
        "# torch.cholesky_solve\n",
        "# torch.solve\n",
        "# torch.triangular_solve\n",
        "# torch.lu\n",
        "# torch.lu_solve\n",
        "# torch.qr\n",
        "# torch.svd\n",
        "# torch.scd_lowrank\n",
        "# torch.pca_lowrank\n",
        "# torch.symeig -> Eigenvalues and vectors for symetric matrices\n",
        "# torch.matrix_power\n",
        "# torch.matrix_rank\n",
        "# torch.eig\n",
        "# torch.det\n",
        "# torch.logdet\n",
        "# torch.slogdet\n",
        "# torch.trace\n",
        "# torch.tril -> Returns the lower triangular part of input\n",
        "# torch.triu\n",
        "# torch.lstsq\n",
        "# torch.inverse  -> same as np.inv\n",
        "# torch.pinverse -> same as np.pinv\n",
        "# torch.flatten\n",
        "# torch.norm -> Computes the norm of a matrix or vector\n",
        "# torch.add -> Can be used as axpy but for tensors\n",
        "# torch.addcdiv -> Performs the element-wise division of `tensor1` by `tensor2`,\n",
        "#                  multiply the result by the scalar `value` and add it to `input`\n",
        "#                  result = input + value * (tensor1 / tensor2)\n",
        "# torch.addcmul -> Same as addcdiv but for multiplecation\n",
        "# torch.bitwise_not -> oeprator |\n",
        "# torch.bitwise_and -> operator &\n",
        "# torch.bitwise_not\n",
        "# torch.bitwise_xor\n",
        "# torch.ceil\n",
        "# torch.floor\n",
        "# torch.angle -> Commutes the angle of each vector (complex number function)\n",
        "# torch.conj -> Computes the conjugate of each vector (complex number function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tADWFzJiF4LZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ddf2bbb4-673d-45bb-e290-db78a9bc467c"
      },
      "source": [
        "# torch.clamp -> works like `np.clip`. Clips a tensor in [min, max] range\n",
        "a = torch.arange(0, 20)\n",
        "print(a)\n",
        "a = torch.clamp(a, min=5, max=15)\n",
        "print(a)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19])\n",
            "tensor([ 5,  5,  5,  5,  5,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 15, 15,\n",
            "        15, 15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CQEJfsoIRM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Advanced Mathematical Operations\n",
        "# torch.digamma -> Derivative of log of gamma function => d/dx ( ln(gamma(input)) )\n",
        "# torch.erf -> Error function\n",
        "# torch.erfc -> Complement of the error function\n",
        "# torch.erfinv -> Inverse of the error function\n",
        "# torch.exp\n",
        "# torch.expm1\n",
        "# torch.log1p -> inverse of torch.expm1\n",
        "# torch.floor_devide\n",
        "# torch.fmod -> Float %\n",
        "# torch.frac -> Computes the fractional portion of each element in `input`\n",
        "# torch.lerp -> out = start + weight * (end - start)\n",
        "# torch.lgamma -> Logirithm of the gamma function\n",
        "# torch.mvlgamma -> Compute the multivariate log gamma function\n",
        "# torch.polygamma -> Compute the n'th derivative of `torch.digamma` function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUAti9avJivi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comparison Ops\n",
        "# torch.equal\n",
        "# torch.eq\n",
        "# torch.ne\n",
        "# torch.ge\n",
        "# torch.le\n",
        "# torch.gt\n",
        "# torch.lt\n",
        "# torch.allclose\n",
        "# torch.isfinite\n",
        "# torch.isinf\n",
        "# torch.isnan\n",
        "# torch.kthvalue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYgrPg-5S7rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.sort\n",
        "# torch.argsort\n",
        "# torch.topk\n",
        "# torch.kthvalue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEISpvkXfnrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: BLAS and LAPACK functions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XURzQke-fr0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "64132772-cf5c-4255-9662-de30d2816fa9"
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "#                           NEURAL NETWORKS IN PYTORCH                          #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "torch.set_default_dtype(torch.float32)\n",
        "torch.seed(42)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ede861940696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: seed() takes 0 positional arguments but 1 was given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXDg8dEpiG7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.nn.Parameter -> Registers a parameter in the scope of the module.\n",
        "#                       Doesn't backpropogate if used in or from other module,\n",
        "#                       unless registered.\n",
        "a = torch.randn(4, 5)\n",
        "print(a)\n",
        "nn.Parameter(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXW5LTQfiW-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.nn.module -> A class to create your NN. Define `__init__` to\n",
        "#                    initialize model parameters and `forward` method\n",
        "#                    to define operations on the parameters and input.\n",
        "#                    Registered parameters will be backpropogated while\n",
        "#                    training.\n",
        "class LinearRegressor(nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(LinearRegressor, self).__init__()\n",
        "        self.w = nn.Parameter(torch.randn(n_features, 1))\n",
        "        self.b = nn.Parameter(torch.randn(1))\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X @ self.w + self.b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9XskQqioFbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d8d15b6d-06aa-4ec4-cecf-79b466051c8d"
      },
      "source": [
        "# Preparing Data\n",
        "import matplotlib.pyplot as plt\n",
        "n_examples = 10\n",
        "n_features = 1\n",
        "X = torch.randn(n_examples, n_features)\n",
        "w_true = torch.randn(n_features, 1)\n",
        "b_true = torch.randn(1)\n",
        "y_true = X @ w_true + b_true + 0.1 * torch.randn(n_examples, 1)\n",
        "plt.scatter(X, y_true)\n",
        "plt.title('Generated Data')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7y2XJ7BlOjG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "138ee1fa-4488-465b-d3e3-a2b46ca6b39d"
      },
      "source": [
        "# Initialize the LinearRegressor model.\n",
        "model = LinearRegressor(n_features)\n",
        "print(model(X))\n",
        "# .parameters() `yields` the parameters.\n",
        "# Not a list of parameters.\n",
        "print([i for i in model.parameters()])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2805],\n",
            "        [ 1.0515],\n",
            "        [ 0.9613],\n",
            "        [ 1.1956],\n",
            "        [ 0.2658],\n",
            "        [-0.1470],\n",
            "        [ 1.0280],\n",
            "        [-0.4521],\n",
            "        [ 0.7524],\n",
            "        [ 0.8356]], grad_fn=<AddBackward0>)\n",
            "[Parameter containing:\n",
            "tensor([[0.8412]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4103], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr4CTh9SnKLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f2fa933-165b-48b7-b0e3-03b3a5657901"
      },
      "source": [
        "# Training a torch.nn.Module() model\n",
        "from time import sleep\n",
        "from sys import stdout\n",
        "epochs = 200\n",
        "# torch.nn contains many loss functions. We use\n",
        "# mse loss with mean over all the examples.\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "# torch.optim contains many optimizers like Adam, Momentum\n",
        "# SGD, Adagrad, Adadelta, RMSProp, Nesterov Momentum, etc\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Let's define our training loop now!\n",
        "for i in range(epochs):\n",
        "    y_pred = model(X) # Compute the prediction by forward propogating\n",
        "\n",
        "    loss = loss_fn(y_pred, y_true) # Evaluate the loss function\n",
        "    # Print the loss\n",
        "    stdout.write(f'\\repoch: {i} \\t {20*\"\"}')\n",
        "    stdout.write(f'\\repoch: {i} \\t loss: {loss.item():.3f}')\n",
        "    optimizer.zero_grad() # Initialize the optimizer\n",
        "    # Backpropogate through the graph. This will compute the\n",
        "    # gradients of all the parameters in-place and store them\n",
        "    # in .grad() method of the parameters.\n",
        "    loss.backward()\n",
        "    optimizer.step() # Take one step of optimizer. This will update our parameters.\n",
        "    sleep(0.2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 199 \t loss: 0.003"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06D8Kj1Qp2uY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "5c499188-0875-4ef2-8616-2d0ceb3dbb6d"
      },
      "source": [
        "# Let's see how good did we perform\n",
        "print(w_true)\n",
        "print(b_true)\n",
        "params = [i for i in model.parameters()]\n",
        "print(params[0])\n",
        "print(params[1])\n",
        "print(y_true)\n",
        "print(model(X))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5834]])\n",
            "tensor([-0.1838])\n",
            "Parameter containing:\n",
            "tensor([[0.5585]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1567], requires_grad=True)\n",
            "tensor([[-0.1867],\n",
            "        [ 0.2643],\n",
            "        [ 0.2029],\n",
            "        [ 0.3468],\n",
            "        [-0.2486],\n",
            "        [-0.4373],\n",
            "        [ 0.1759],\n",
            "        [-0.7716],\n",
            "        [-0.0092],\n",
            "        [ 0.1486]])\n",
            "tensor([[-0.2429],\n",
            "        [ 0.2690],\n",
            "        [ 0.2091],\n",
            "        [ 0.3647],\n",
            "        [-0.2527],\n",
            "        [-0.5267],\n",
            "        [ 0.2534],\n",
            "        [-0.7293],\n",
            "        [ 0.0704],\n",
            "        [ 0.1257]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f9VmRAQq3O4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}