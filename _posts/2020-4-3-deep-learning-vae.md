---
type: post
title: Variational Auto-Encoders in Deep Learning
subtitle: Deep Learning Course - Part 2. Learn how to implement generative models in Python.
image: /images/graphical_models/vae_logo.png
gh-repo: tirthasheshpatel/Generative-Models
gh-badge: [star, fork, follow]
tags: [Deep Learning, Machine Learning]
---

## Influence and Reference

This article is highly influenced by the [NPTEL's Deep Learning - Part 2 course by Mitesh Khapra](https://nptel.ac.in/courses/106/106/106106201/) and uses its material reserving all the rights to their corresponding authors. This article contains a full implementation of Restricted Boltzmann Machines using pure NumPy and no other 3rd party frameworks.

### Code

The code is available both on colab and GitHub.

1. **Colab Link** : [![launch in Colab](https://img.shields.io/badge/Open%20in-Colab-yellowgreen)](https://colab.research.google.com/drive/1dGjafQOqi2wdXvZK_QfLCrGa4hjtz_EA)

2. **GitHub Link**: [![launch on GitHub](https://img.shields.io/badge/Open%20on-GitHub-blue)](https://github.com/tirthasheshpatel/Generative-Models)

### Table of Contents

- [Auto-Encoders Review](#auto-encoders-review)
- [Variational Auto-Encoders as Neural Networks](#variational-auto-encoder-as-neural-networks)
- [Variational Auto-Encoders as Graphical Models](#variational-auto-encoder-as-graphical-models)

### Auto-Encoders Review

### Variational Auto-Encoders as Neural Networks

### Variational Auto-Encoders as Graphical Models
