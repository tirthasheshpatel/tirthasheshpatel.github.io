---
layout: post
title: GSoC Week 1 - Latent GP model and Covariance functions!
subtitle: Work done on my GSoC project in Week 1 for PyMC4 project.
gsoc_post: true
tags: [GSoC 2020]
comments: true
permalink: /gsoc2020/latent-gp-model-and-covariance-functions
---

## Week 1 with PyMC4...

This has been a really good week for me. I proposed a major pull request implementing a basic Gaussain Process Interface in PyMC4 on March 1 got merged onto master this June. It gave me an essence of the development environment I was working in. It helped me make some design changes for my next PR. Also, I was able to do some doc fixes that I introduced in the former PRs.

## ENH: Add Basic Gaussian Process Interface

[#235: ENH: Add Basic Gaussian Process Interface](https://github.com/pymc-devs/pymc4/pull/235)

It was really nice to see this get merged in. This was a very basic proposal that has many flaws. I dedicated this week to identify and fix all the bugs or flaws shipped onto master with this PR.

Specifically, I fixed all the documentation errors and the covariance function base class making it easier to build on it and porting in new features for arbitary shaped tensors. I also added loads of tests and assure everything works on point.

## ENH: add constant and white noise kernel, fix docs and tests

[#272: ENH: add constant and white noise kernel, fix docs and tests](https://github.com/pymc-devs/pymc4/pull/272)

This PR implements all the new features I mentioned in the above section. Specifically, I rewrite the `Covariance` base class for all the covariance functions and added more covariance functions on that base. The new features include:

- **Changes in the `Covariance` base class**:
  - add `diag` parameter: If true, only evaulates the diagonal of the full covariance matrix.
  - add `active_dims` parameter in the covriance function base class: The columns to operate on. If `None`, defaults to using all the columns of all the feature_ndims dimensions. The leftmost `len(active_dims)` are considered for evaluation and not the rightmost dims.
  - add `scale_diag` parameter: Scaling parameter of lenght_scale for performing ARD. Ignored if keyword argument `ARD=False`.
- **Add `Constant` kernel**: Constant kernel just evaluates to a constant value in the covarinace matrix and point evaluations irrespective of the input. It is very useful as a lightweight kernel when speed and performace is a need. It doesn't evaluate a complex function and so its gradients are faster and easier to compute.
- **Add `WhiteNoise` kernel**: This kernel adds some noise to the covariance functions and is mostly used to stabilize other PSD kernels. This helps them become non-singular and makes cholesky decomposition possible for sampling from the `MvNormalCholesky` distribution. It is recommended to use this kernel in combination with other covariance/kernel function when working with GP on large data.
- **Changes in the covariance combination class (`_Sum` and `_Prod`)**:
  - These are all private changes not visible to the user. Previously, nestel function calls were made to evaulate the kernel which made it in-efficient to combine multiple covariance functions together. I refactored the class to efficiently combine covariance functions.
- **Tests**:
  - Add a test suite for mean and covariance functions.
  - Add a test suite for GP models implemented till now.
- **Benchmaring**:
  - Benchmaking is not officially done by the PyMC team and so I had to make some unofficial benchmakes. You can access the benchmarks at [this colab notebook](https://colab.research.google.com/drive/1JQ17NyiFCopbiMjfMmoFVXDtoQr4S-qG?usp=sharing) or [this notebook on github](https://github.com/tirthasheshpatel/OOP-in-Python/blob/master/Performance_Review_PyMC3%2C_PyMC4.ipynb).

## MAINT: add reparameterize to gp and fix mvnormal

[#269: MAINT: add reparameterize to gp and fix mvnormal](https://github.com/pymc-devs/pymc4/pull/269)

This is a small PR adding the functionality to reparameterize the GP prior and conditional distributions for better numerical accuracy. I will work more on gaussian processes in Week 3. I want to all and finish up with the mean and covariance functions in Week 2 before I proceed to GP Models in Week 3.
